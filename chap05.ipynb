{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5ff593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv('GG_API_KEY')\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a214495a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c0fc73",
   "metadata": {},
   "source": [
    "#### Architecture #1: LLM Call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4335aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` \n",
    "    # function in the annotation defines how this state should \n",
    "    # be updated (in this case, it appends new messages to the \n",
    "    # list, rather than replacing the previous messages)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot(state: State):\n",
    "    answer = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": [answer]}\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"chatbot\", chatbot)\n",
    "builder.add_edge(START, 'chatbot')\n",
    "builder.add_edge('chatbot', END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3817101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chatbot': {'messages': [AIMessage(content='Hi there! How can I help you today?', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--0a6dd5fd-cfd8-4cbb-8fa9-9cbb8808a5e3-0', usage_metadata={'input_tokens': 2, 'output_tokens': 11, 'total_tokens': 13, 'input_token_details': {'cache_read': 0}})]}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "input = {\"messages\": [HumanMessage('hi!')]}\n",
    "for chunk in graph.stream(input):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97020984",
   "metadata": {},
   "source": [
    "#### Architecture #2: Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fe3ab72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_low_temp = llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "model_high_temp = llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "424c03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    sql_query: str\n",
    "    sql_explanation: str\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "class Output(TypedDict):\n",
    "    sql_query: str\n",
    "    sql_explanation: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e08b0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "generate_prompt = SystemMessage(\n",
    "    \"\"\"You are a helpful data analyst who generates SQL queries for users based \n",
    "    on their questions.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4418753a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sql(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [generate_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_query\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c36c1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_prompt = SystemMessage(\n",
    "    \"You are a helpful data analyst who explains SQL queries to users.\"\n",
    ")\n",
    "\n",
    "def explain_sql(state: State) -> State:\n",
    "    messages = [\n",
    "        explain_prompt,\n",
    "        # contains user's query and SQL query from prev step\n",
    "        *state[\"messages\"],\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"sql_explanation\": res.content,\n",
    "        # update conversation history\n",
    "        \"messages\": res,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cbc82a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State, input_schema=Input, output_schema=Output)\n",
    "builder.add_node(\"generate_sql\", generate_sql)\n",
    "builder.add_node(\"explain_sql\", explain_sql)\n",
    "builder.add_edge(START, \"generate_sql\")\n",
    "builder.add_edge(\"generate_sql\", \"explain_sql\")\n",
    "builder.add_edge(\"explain_sql\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9afbcf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sql_query': '```sql\\nSELECT\\n    product_name,\\n    SUM(sales) AS total_sales\\nFROM\\n    sales_table\\nGROUP BY\\n    product_name;\\n```',\n",
       " 'sql_explanation': \"\\n\\nOkay, I can help you understand this SQL query!  Let's break it down:\\n\\n**Purpose:**\\n\\nThe query is designed to calculate the total sales amount for each distinct product in your sales data.\\n\\n**Explanation:**\\n\\n1.  **`SELECT product_name, SUM(sales) AS total_sales`**:\\n    *   `SELECT product_name`: This specifies that you want to retrieve the name of the product in your result.\\n    *   `SUM(sales)`: This is an aggregate function that calculates the sum of the `sales` column.  `SUM()` adds up all the sales values for each group (defined later by the `GROUP BY` clause).\\n    *   `AS total_sales`: This assigns an alias (a temporary name) to the calculated sum of sales.  Instead of the column being named `SUM(sales)`, it will be named `total_sales` in the output, which is more descriptive.\\n\\n2.  **`FROM sales_table`**:\\n    *   `FROM sales_table`: This indicates that you're retrieving data from a table named `sales_table`.  You'll need to replace `sales_table` with the actual name of your table that contains the sales data.  This table should have at least two columns: `product_name` and `sales`.\\n\\n3.  **`GROUP BY product_name`**:\\n    *   `GROUP BY product_name`: This is the crucial part that groups the rows in your `sales_table` based on the `product_name`.  The `SUM(sales)` function is applied to each of these groups.  So, all rows with the same `product_name` will be grouped together, and their sales values will be summed up.\\n\\n**In Summary:**\\n\\nThe query groups all the rows in the `sales_table` by `product_name`.  Then, for each group of rows (i.e., for each unique product), it calculates the sum of the `sales` and displays it along with the `product_name`.\\n\\n**Example:**\\n\\nLet's say your `sales_table` looks like this:\\n\\n| product\\\\_name | sales |\\n| :------------ | :---- |\\n| Widget A      | 10    |\\n| Widget B      | 20    |\\n| Widget A      | 15    |\\n| Widget C      | 30    |\\n| Widget B      | 25    |\\n\\nThe query would return:\\n\\n| product\\\\_name | total\\\\_sales |\\n| :------------ | :----------- |\\n| Widget A      | 25           |\\n| Widget B      | 45           |\\n| Widget C      | 30           |\\n\\n**Important:**\\n\\n*   Make sure that the `sales_table` name and the column names (`product_name`, `sales`) in the query match the actual names in your database.\\n*   The `sales` column should be a numeric data type (e.g., INTEGER, DECIMAL, FLOAT) so that the `SUM()` function can work correctly.\\n\\nI hope this explanation is clear and helpful!  Let me know if you have any other questions.\"}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke({\n",
    "  \"user_query\": \"What is the total sales for each product?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "113a6d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'generate_sql': {'sql_query': '```sql\\nSELECT\\n    product_name,\\n    SUM(sales) AS total_sales\\nFROM\\n    sales_table\\nGROUP BY\\n    product_name;\\n```', 'messages': [HumanMessage(content='What is the total sales for each product?', additional_kwargs={}, response_metadata={}, id='11fea22b-0c73-40f2-9ca8-9f6e7cd4aae3'), AIMessage(content='```sql\\nSELECT\\n    product_name,\\n    SUM(sales) AS total_sales\\nFROM\\n    sales_table\\nGROUP BY\\n    product_name;\\n```', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ae89aaa7-24d5-4a52-a1c5-e6254bc7fe5c-0', usage_metadata={'input_tokens': 29, 'output_tokens': 38, 'total_tokens': 67, 'input_token_details': {'cache_read': 0}})]}}\n",
      "{'explain_sql': {'sql_explanation': '\\n\\n**Explanation:**\\n\\n1.  **`SELECT product_name, SUM(sales) AS total_sales`**:\\n    *   This part specifies what we want to retrieve.\\n    *   `product_name`: We want to see the name of each product.\\n    *   `SUM(sales)`:  This is an aggregate function that calculates the sum of the `sales` column for each group.\\n    *   `AS total_sales`:  This gives the calculated sum a more descriptive name, \"total\\\\_sales\".\\n\\n2.  **`FROM sales_table`**:\\n    *   This indicates that we\\'re getting the data from a table named `sales_table`.  You\\'ll need to replace `sales_table` with the actual name of your table.  The table should contain columns like `product_name` and `sales`.\\n\\n3.  **`GROUP BY product_name`**:\\n    *   This is the crucial part that groups the rows based on the `product_name`.  The `SUM(sales)` function then calculates the sum of sales for each *distinct* product name.  Without `GROUP BY`, you\\'d just get the total sales for *all* products combined.\\n\\n**In simpler terms:**\\n\\nImagine you have a table of sales records. Each record has the product sold and the amount of the sale.  This query goes through the table, groups all the sales records for the same product together, and then adds up the sales amounts for each product. The result is a list of each product and its total sales.\\n\\n**Example:**\\n\\nIf your `sales_table` looked like this:\\n\\n| product\\\\_name | sales |\\n| :------------- | :---- |\\n| Apple          | 2.00  |\\n| Banana         | 1.00  |\\n| Apple          | 2.50  |\\n| Orange         | 1.50  |\\n| Banana         | 1.25  |\\n\\nThe query would return:\\n\\n| product\\\\_name | total\\\\_sales |\\n| :------------- | :------------- |\\n| Apple          | 4.50         |\\n| Banana         | 2.25         |\\n| Orange         | 1.50         |\\n\\n**Important Considerations:**\\n\\n*   **Table and Column Names:** Make sure you replace `sales_table`, `product_name`, and `sales` with the *actual* names of your table and columns in your database.\\n*   **Data Types:** The `sales` column should be a numeric data type (e.g., INTEGER, DECIMAL, FLOAT) so that the `SUM()` function can work correctly.\\n*   **Null Values:**  If your `sales` column contains `NULL` values, `SUM()` will treat them as zero.  If you need to handle `NULL` values differently (e.g., exclude records with `NULL` sales), you might need to add a `WHERE` clause to filter them out: `WHERE sales IS NOT NULL`.\\n*   **Database System:**  This SQL query is fairly standard and should work in most relational database systems (like MySQL, PostgreSQL, SQL Server, Oracle, SQLite).  However, minor syntax variations might be needed depending on the specific database system you are using.', 'messages': AIMessage(content='\\n\\n**Explanation:**\\n\\n1.  **`SELECT product_name, SUM(sales) AS total_sales`**:\\n    *   This part specifies what we want to retrieve.\\n    *   `product_name`: We want to see the name of each product.\\n    *   `SUM(sales)`:  This is an aggregate function that calculates the sum of the `sales` column for each group.\\n    *   `AS total_sales`:  This gives the calculated sum a more descriptive name, \"total\\\\_sales\".\\n\\n2.  **`FROM sales_table`**:\\n    *   This indicates that we\\'re getting the data from a table named `sales_table`.  You\\'ll need to replace `sales_table` with the actual name of your table.  The table should contain columns like `product_name` and `sales`.\\n\\n3.  **`GROUP BY product_name`**:\\n    *   This is the crucial part that groups the rows based on the `product_name`.  The `SUM(sales)` function then calculates the sum of sales for each *distinct* product name.  Without `GROUP BY`, you\\'d just get the total sales for *all* products combined.\\n\\n**In simpler terms:**\\n\\nImagine you have a table of sales records. Each record has the product sold and the amount of the sale.  This query goes through the table, groups all the sales records for the same product together, and then adds up the sales amounts for each product. The result is a list of each product and its total sales.\\n\\n**Example:**\\n\\nIf your `sales_table` looked like this:\\n\\n| product\\\\_name | sales |\\n| :------------- | :---- |\\n| Apple          | 2.00  |\\n| Banana         | 1.00  |\\n| Apple          | 2.50  |\\n| Orange         | 1.50  |\\n| Banana         | 1.25  |\\n\\nThe query would return:\\n\\n| product\\\\_name | total\\\\_sales |\\n| :------------- | :------------- |\\n| Apple          | 4.50         |\\n| Banana         | 2.25         |\\n| Orange         | 1.50         |\\n\\n**Important Considerations:**\\n\\n*   **Table and Column Names:** Make sure you replace `sales_table`, `product_name`, and `sales` with the *actual* names of your table and columns in your database.\\n*   **Data Types:** The `sales` column should be a numeric data type (e.g., INTEGER, DECIMAL, FLOAT) so that the `SUM()` function can work correctly.\\n*   **Null Values:**  If your `sales` column contains `NULL` values, `SUM()` will treat them as zero.  If you need to handle `NULL` values differently (e.g., exclude records with `NULL` sales), you might need to add a `WHERE` clause to filter them out: `WHERE sales IS NOT NULL`.\\n*   **Database System:**  This SQL query is fairly standard and should work in most relational database systems (like MySQL, PostgreSQL, SQL Server, Oracle, SQLite).  However, minor syntax variations might be needed depending on the specific database system you are using.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--2d1fb141-2ff8-4928-8740-da10e154ca9c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 702, 'total_tokens': 762, 'input_token_details': {'cache_read': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream({\n",
    "  \"user_query\": \"What is the total sales for each product?\"\n",
    "}):\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4fb27d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = graph.get_graph().draw_mermaid_png()\n",
    "filename = \"my_langgraph_workflow_2.png\"\n",
    "try:\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(img)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733740c",
   "metadata": {},
   "source": [
    "#### Architecture #3: Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15ffcf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Literal, TypedDict\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.vectorstores.in_memory import InMemoryVectorStore\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba469571",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "model_low_temp = llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.1,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "model_high_temp = llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da12af22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # to track conversation history\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # input\n",
    "    user_query: str\n",
    "    # output\n",
    "    domain: Literal[\"records\", \"insurance\"]\n",
    "    documents: list[Document]\n",
    "    answer: str\n",
    "\n",
    "class Input(TypedDict):\n",
    "    user_query: str\n",
    "\n",
    "class Output(TypedDict):\n",
    "    documents: list[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288917a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_records_store = InMemoryVectorStore.from_documents([], embeddings)\n",
    "medical_records_retriever = medical_records_store.as_retriever()\n",
    "\n",
    "insurance_faqs_store = InMemoryVectorStore.from_documents([], embeddings)\n",
    "insurance_faqs_retriever = insurance_faqs_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ac9dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = SystemMessage(\n",
    "    \"\"\"You need to decide which domain to route the user query to. You have two \n",
    "        domains to choose from:\n",
    "          - records: contains medical records of the patient, such as \n",
    "          diagnosis, treatment, and prescriptions.\n",
    "          - insurance: contains frequently asked questions about insurance \n",
    "          policies, claims, and coverage.\n",
    "\n",
    "Output only the domain name.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec1d4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_node(state: State) -> State:\n",
    "    user_message = HumanMessage(state[\"user_query\"])\n",
    "    messages = [router_prompt, *state[\"messages\"], user_message]\n",
    "    res = model_low_temp.invoke(messages)\n",
    "    return {\n",
    "        \"domain\": res.content,# update conversation history\n",
    "        \"messages\": [user_message, res],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3877c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_retriever(\n",
    "    state: State,\n",
    ") -> Literal[\"retrieve_medical_records\", \"retrieve_insurance_faqs\"]:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        return \"retrieve_medical_records\"\n",
    "    else:\n",
    "        return \"retrieve_insurance_faqs\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "60629ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_medical_records(state: State) -> State:\n",
    "    documents = medical_records_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }\n",
    "\n",
    "def retrieve_insurance_faqs(state: State) -> State:\n",
    "    documents = insurance_faqs_retriever.invoke(state[\"user_query\"])\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6f2e11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_records_prompt = SystemMessage(\n",
    "    \"\"\"You are a helpful medical chatbot who answers questions based on the \n",
    "        patient's medical records, such as diagnosis, treatment, and \n",
    "        prescriptions.\"\"\"\n",
    ")\n",
    "\n",
    "insurance_faqs_prompt = SystemMessage(\n",
    "    \"\"\"You are a helpful medical insurance chatbot who answers frequently asked \n",
    "        questions about insurance policies, claims, and coverage.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "366f9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(state: State) -> State:\n",
    "    if state[\"domain\"] == \"records\":\n",
    "        prompt = medical_records_prompt\n",
    "    else:\n",
    "        prompt = insurance_faqs_prompt\n",
    "    messages = [\n",
    "        prompt,\n",
    "        *state[\"messages\"],\n",
    "        HumanMessage(f'Documents: {state[\"documents\"]}'),\n",
    "    ]\n",
    "    res = model_high_temp.invoke(messages)\n",
    "    return {\n",
    "        \"answer\": res.content,# update conversation history\n",
    "        \"messages\": res,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5899b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(State, input_schema=Input, output_schema=Output)\n",
    "builder.add_node(\"router\", router_node)\n",
    "builder.add_node(\"retrieve_medical_records\", retrieve_medical_records)\n",
    "builder.add_node(\"retrieve_insurance_faqs\", retrieve_insurance_faqs)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "builder.add_edge(START, \"router\")\n",
    "builder.add_conditional_edges(\"router\", pick_retriever)\n",
    "builder.add_edge(\"retrieve_medical_records\", \"generate_answer\")\n",
    "builder.add_edge(\"retrieve_insurance_faqs\", \"generate_answer\")\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "135f4a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = graph.get_graph().draw_mermaid_png()\n",
    "filename = \"my_langgraph_workflow_3.png\"\n",
    "try:\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(img)\n",
    "except:\n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbc244a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'router': {'domain': 'insurance', 'messages': [HumanMessage(content='Am I covered for COVID-19 treatment?', additional_kwargs={}, response_metadata={}, id='fc208307-328f-4608-962d-65328e1b3ba9'), AIMessage(content='insurance', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--f5d6f606-da7a-4ebc-bbbd-b946a763ffdd-0', usage_metadata={'input_tokens': 86, 'output_tokens': 2, 'total_tokens': 88, 'input_token_details': {'cache_read': 0}})]}}\n",
      "{'retrieve_insurance_faqs': {'documents': []}}\n",
      "{'generate_answer': {'answer': 'Yes, your policy covers COVID-19 treatment. Please check your policy \\n        documents for specific details on coverage limits and cost-sharing.', 'messages': AIMessage(content='Yes, your policy covers COVID-19 treatment. Please check your policy \\n        documents for specific details on coverage limits and cost-sharing.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--dda5bb46-c3a1-4a99-8e9e-72a9bce0e0b2-0', usage_metadata={'input_tokens': 38, 'output_tokens': 30, 'total_tokens': 68, 'input_token_details': {'cache_read': 0}})}}\n"
     ]
    }
   ],
   "source": [
    "input = {\n",
    "    \"user_query\": \"Am I covered for COVID-19 treatment?\"\n",
    "}\n",
    "for c in graph.stream(input):\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2383ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
